{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reference\n",
    "- https://github.com/kyuing/TIL/blob/master/python_img_crawling/google.py\n",
    "- https://chromedriver.chromium.org/getting-started\n",
    "- ###  Huge thanks to \"itopia\". ref at https://osh88itopia.tistory.com/86 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request #import urllib.request\n",
    "from bs4 import BeautifulSoup #import BeautifulSoup\n",
    "from selenium import webdriver #import webdriver\n",
    "from selenium.webdriver.common.keys import Keys #import Keys\n",
    "import time #import time; enablues you to use .sleep() while crwaling imges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 라운드넥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate browser\n",
    "#binary = r'C:\\Users\\HP\\Desktop\\chromedriver\\chromedriver.exe' #path to the chrome driver\n",
    "#browser = webdriver.Chrome(binary) #init browser - # Optional argument, if not specified will search path.\n",
    "browser = webdriver.Chrome() #init browser\n",
    "\n",
    "#get browser. this will open a new ready-for-searching tab of Chrome browser\n",
    "browser.get(\"https://www.google.com/imghp?hl=en&search?hl=en&q=\") \n",
    "\n",
    "elem = browser.find_element_by_name(\"q\") #init elem\n",
    "elem.send_keys(\"라운드넥\") #keywords that you wanna use to search\n",
    "time.sleep(3)\n",
    "elem.submit() #elem.submit()\n",
    "\n",
    "# for-loop \n",
    "for i in range(1 ,6):\n",
    "    # find body tag and execute send_keys(Keys.END) for i < 10 so 9 times\n",
    "    # Keys.END is when the END key is executed to be cliecked\n",
    "    browser.find_element_by_xpath(\"//body\").send_keys(Keys.END)  #smb == when clicking show more result button\n",
    "    try:\n",
    "        browser.find_element_by_id(\"smb\").click()\n",
    "        time.sleep(5)\n",
    "    except:\n",
    "        time.sleep(5)\n",
    "time.sleep(5)\n",
    "\n",
    "html = browser.page_source # get page_source from browser\n",
    "\n",
    "# init soup by calling the method BeautifulSoup with the parameters; the variable html and \"html.parser\"\n",
    "soup = BeautifulSoup(html, \"html.parser\") #this code enables you to fetch the image urls and download the images\n",
    "\n",
    "# method for listing url\n",
    "def fetch_list_url():\n",
    "    params = [] #declare and init an array\n",
    "\n",
    "    # find all img tags and the class whose name is rg_i\n",
    "    imgList = soup.find_all(\"img\", class_ =\"rg_i\")\n",
    "\n",
    "    #Now, extract the img sources(urls) from imgList\n",
    "    for im in imgList:\n",
    "        try:\n",
    "            params.append(im[\"src\"]) #source address of an img in the class rg_i\n",
    "        except KeyError:\n",
    "            params.append(im[\"data-src\"])\n",
    "    return params #return params`\n",
    "\n",
    "# method for downloading imgs from the url\n",
    "def fetch_detail_url():\n",
    "    params = fetch_list_url() #init params by calling the method fetch_list_url()\n",
    "\n",
    "    # print(params)\n",
    "    a = 1 #a = 1\n",
    "    for p in params:\n",
    "        # @param p. the source img urls in params are assigned into p with this foreach-loop if urls are fetched properly   \n",
    "        # @param path; gives download path\n",
    "        # @param a; gives auto-incrementing numeric file name\n",
    "        # finally, set .jpg extension to each of the img downloaded.\n",
    "        urllib.request.urlretrieve(p, 'neckline/1_round_neck/' + str(a) + \".jpg\" )\n",
    "        a+=1 #a = a + 1; increment nums\n",
    "\n",
    "#by calling the method fetch_detail_url(), the method fetch_list_url() is executed first in it.\n",
    "fetch_detail_url() #fetch_detail_url()\n",
    "browser.quit() #close the browser\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 보트넥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate browser\n",
    "#binary = r'C:\\Users\\HP\\Desktop\\chromedriver\\chromedriver.exe' #path to the chrome driver\n",
    "#browser = webdriver.Chrome(binary) #init browser - # Optional argument, if not specified will search path.\n",
    "browser = webdriver.Chrome() #init browser\n",
    "\n",
    "#get browser. this will open a new ready-for-searching tab of Chrome browser\n",
    "browser.get(\"https://www.google.com/imghp?hl=en&search?hl=en&q=\") \n",
    "\n",
    "elem = browser.find_element_by_name(\"q\") #init elem\n",
    "elem.send_keys(\"보트넥\") #keywords that you wanna use to search\n",
    "time.sleep(3)\n",
    "elem.submit() #elem.submit()\n",
    "\n",
    "# for-loop \n",
    "for i in range(1 ,6):\n",
    "    # find body tag and execute send_keys(Keys.END) for i < 10 so 9 times\n",
    "    # Keys.END is when the END key is executed to be cliecked\n",
    "    browser.find_element_by_xpath(\"//body\").send_keys(Keys.END)  #smb == when clicking show more result button\n",
    "    try:\n",
    "        browser.find_element_by_id(\"smb\").click()\n",
    "        time.sleep(5)\n",
    "    except:\n",
    "        time.sleep(5)\n",
    "time.sleep(5)\n",
    "\n",
    "html = browser.page_source # get page_source from browser\n",
    "\n",
    "# init soup by calling the method BeautifulSoup with the parameters; the variable html and \"html.parser\"\n",
    "soup = BeautifulSoup(html, \"html.parser\") #this code enables you to fetch the image urls and download the images\n",
    "\n",
    "# method for listing url\n",
    "def fetch_list_url():\n",
    "    params = [] #declare and init an array\n",
    "\n",
    "    # find all img tags and the class whose name is rg_i\n",
    "    imgList = soup.find_all(\"img\", class_ =\"rg_i\")\n",
    "\n",
    "    #Now, extract the img sources(urls) from imgList\n",
    "    for im in imgList:\n",
    "        try:\n",
    "            params.append(im[\"src\"]) #source address of an img in the class rg_i\n",
    "        except KeyError:\n",
    "            params.append(im[\"data-src\"])\n",
    "    return params #return params`\n",
    "\n",
    "# method for downloading imgs from the url\n",
    "def fetch_detail_url():\n",
    "    params = fetch_list_url() #init params by calling the method fetch_list_url()\n",
    "\n",
    "    # print(params)\n",
    "    a = 1 #a = 1\n",
    "    for p in params:\n",
    "        # @param p. the source img urls in params are assigned into p with this foreach-loop if urls are fetched properly   \n",
    "        # @param path; gives download path\n",
    "        # @param a; gives auto-incrementing numeric file name\n",
    "        # finally, set .jpg extension to each of the img downloaded.\n",
    "        urllib.request.urlretrieve(p, 'neckline/2_1_boat_neck/' + str(a) + \".jpg\" )\n",
    "        a+=1 #a = a + 1; increment nums\n",
    "\n",
    "#by calling the method fetch_detail_url(), the method fetch_list_url() is executed first in it.\n",
    "fetch_detail_url() #fetch_detail_url()\n",
    "browser.quit() #close the browser\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 입술넥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate browser\n",
    "#binary = r'C:\\Users\\HP\\Desktop\\chromedriver\\chromedriver.exe' #path to the chrome driver\n",
    "#browser = webdriver.Chrome(binary) #init browser - # Optional argument, if not specified will search path.\n",
    "browser = webdriver.Chrome() #init browser\n",
    "\n",
    "#get browser. this will open a new ready-for-searching tab of Chrome browser\n",
    "browser.get(\"https://www.google.com/imghp?hl=en&search?hl=en&q=\") \n",
    "\n",
    "elem = browser.find_element_by_name(\"q\") #init elem\n",
    "elem.send_keys(\"입술넥\") #keywords that you wanna use to search\n",
    "time.sleep(3)\n",
    "elem.submit() #elem.submit()\n",
    "\n",
    "# for-loop \n",
    "for i in range(1 ,6):\n",
    "    # find body tag and execute send_keys(Keys.END) for i < 10 so 9 times\n",
    "    # Keys.END is when the END key is executed to be cliecked\n",
    "    browser.find_element_by_xpath(\"//body\").send_keys(Keys.END)  #smb == when clicking show more result button\n",
    "    try:\n",
    "        browser.find_element_by_id(\"smb\").click()\n",
    "        time.sleep(5)\n",
    "    except:\n",
    "        time.sleep(5)\n",
    "time.sleep(5)\n",
    "\n",
    "html = browser.page_source # get page_source from browser\n",
    "\n",
    "# init soup by calling the method BeautifulSoup with the parameters; the variable html and \"html.parser\"\n",
    "soup = BeautifulSoup(html, \"html.parser\") #this code enables you to fetch the image urls and download the images\n",
    "\n",
    "# method for listing url\n",
    "def fetch_list_url():\n",
    "    params = [] #declare and init an array\n",
    "\n",
    "    # find all img tags and the class whose name is rg_i\n",
    "    imgList = soup.find_all(\"img\", class_ =\"rg_i\")\n",
    "\n",
    "    #Now, extract the img sources(urls) from imgList\n",
    "    for im in imgList:\n",
    "        try:\n",
    "            params.append(im[\"src\"]) #source address of an img in the class rg_i\n",
    "        except KeyError:\n",
    "            params.append(im[\"data-src\"])\n",
    "    return params #return params`\n",
    "\n",
    "# method for downloading imgs from the url\n",
    "def fetch_detail_url():\n",
    "    params = fetch_list_url() #init params by calling the method fetch_list_url()\n",
    "\n",
    "    # print(params)\n",
    "    a = 1 #a = 1\n",
    "    for p in params:\n",
    "        # @param p. the source img urls in params are assigned into p with this foreach-loop if urls are fetched properly   \n",
    "        # @param path; gives download path\n",
    "        # @param a; gives auto-incrementing numeric file name\n",
    "        # finally, set .jpg extension to each of the img downloaded.\n",
    "        urllib.request.urlretrieve(p, 'neckline/2_2_lips_neck/' + str(a) + \".jpg\" )\n",
    "        a+=1 #a = a + 1; increment nums\n",
    "\n",
    "#by calling the method fetch_detail_url(), the method fetch_list_url() is executed first in it.\n",
    "fetch_detail_url() #fetch_detail_url()\n",
    "browser.quit() #close the browser\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 스퀘어넥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate browser\n",
    "#binary = r'C:\\Users\\HP\\Desktop\\chromedriver\\chromedriver.exe' #path to the chrome driver\n",
    "#browser = webdriver.Chrome(binary) #init browser - # Optional argument, if not specified will search path.\n",
    "browser = webdriver.Chrome() #init browser\n",
    "\n",
    "#get browser. this will open a new ready-for-searching tab of Chrome browser\n",
    "browser.get(\"https://www.google.com/imghp?hl=en&search?hl=en&q=\") \n",
    "\n",
    "elem = browser.find_element_by_name(\"q\") #init elem\n",
    "elem.send_keys(\"스퀘어넥\") #keywords that you wanna use to search\n",
    "time.sleep(3)\n",
    "elem.submit() #elem.submit()\n",
    "\n",
    "# for-loop \n",
    "for i in range(1 ,6):\n",
    "    # find body tag and execute send_keys(Keys.END) for i < 10 so 9 times\n",
    "    # Keys.END is when the END key is executed to be cliecked\n",
    "    browser.find_element_by_xpath(\"//body\").send_keys(Keys.END)  #smb == when clicking show more result button\n",
    "    try:\n",
    "        browser.find_element_by_id(\"smb\").click()\n",
    "        time.sleep(5)\n",
    "    except:\n",
    "        time.sleep(5)\n",
    "time.sleep(5)\n",
    "\n",
    "html = browser.page_source # get page_source from browser\n",
    "\n",
    "# init soup by calling the method BeautifulSoup with the parameters; the variable html and \"html.parser\"\n",
    "soup = BeautifulSoup(html, \"html.parser\") #this code enables you to fetch the image urls and download the images\n",
    "\n",
    "# method for listing url\n",
    "def fetch_list_url():\n",
    "    params = [] #declare and init an array\n",
    "\n",
    "    # find all img tags and the class whose name is rg_i\n",
    "    imgList = soup.find_all(\"img\", class_ =\"rg_i\")\n",
    "\n",
    "    #Now, extract the img sources(urls) from imgList\n",
    "    for im in imgList:\n",
    "        try:\n",
    "            params.append(im[\"src\"]) #source address of an img in the class rg_i\n",
    "        except KeyError:\n",
    "            params.append(im[\"data-src\"])\n",
    "    return params #return params`\n",
    "\n",
    "# method for downloading imgs from the url\n",
    "def fetch_detail_url():\n",
    "    params = fetch_list_url() #init params by calling the method fetch_list_url()\n",
    "\n",
    "    # print(params)\n",
    "    a = 1 #a = 1\n",
    "    for p in params:\n",
    "        # @param p. the source img urls in params are assigned into p with this foreach-loop if urls are fetched properly   \n",
    "        # @param path; gives download path\n",
    "        # @param a; gives auto-incrementing numeric file name\n",
    "        # finally, set .jpg extension to each of the img downloaded.\n",
    "        urllib.request.urlretrieve(p, 'neckline/3_square_neck/' + str(a) + \".jpg\" )\n",
    "        a+=1 #a = a + 1; increment nums\n",
    "\n",
    "#by calling the method fetch_detail_url(), the method fetch_list_url() is executed first in it.\n",
    "fetch_detail_url() #fetch_detail_url()\n",
    "browser.quit() #close the browser\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. U넥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate browser\n",
    "#binary = r'C:\\Users\\HP\\Desktop\\chromedriver\\chromedriver.exe' #path to the chrome driver\n",
    "#browser = webdriver.Chrome(binary) #init browser - # Optional argument, if not specified will search path.\n",
    "browser = webdriver.Chrome() #init browser\n",
    "\n",
    "#get browser. this will open a new ready-for-searching tab of Chrome browser\n",
    "browser.get(\"https://www.google.com/imghp?hl=en&search?hl=en&q=\") \n",
    "\n",
    "elem = browser.find_element_by_name(\"q\") #init elem\n",
    "elem.send_keys(\"U넥\") #keywords that you wanna use to search\n",
    "time.sleep(3)\n",
    "elem.submit() #elem.submit()\n",
    "\n",
    "# for-loop \n",
    "for i in range(1 ,6):\n",
    "    # find body tag and execute send_keys(Keys.END) for i < 10 so 9 times\n",
    "    # Keys.END is when the END key is executed to be cliecked\n",
    "    browser.find_element_by_xpath(\"//body\").send_keys(Keys.END)  #smb == when clicking show more result button\n",
    "    try:\n",
    "        browser.find_element_by_id(\"smb\").click()\n",
    "        time.sleep(5)\n",
    "    except:\n",
    "        time.sleep(5)\n",
    "time.sleep(5)\n",
    "\n",
    "html = browser.page_source # get page_source from browser\n",
    "\n",
    "# init soup by calling the method BeautifulSoup with the parameters; the variable html and \"html.parser\"\n",
    "soup = BeautifulSoup(html, \"html.parser\") #this code enables you to fetch the image urls and download the images\n",
    "\n",
    "# method for listing url\n",
    "def fetch_list_url():\n",
    "    params = [] #declare and init an array\n",
    "\n",
    "    # find all img tags and the class whose name is rg_i\n",
    "    imgList = soup.find_all(\"img\", class_ =\"rg_i\")\n",
    "\n",
    "    #Now, extract the img sources(urls) from imgList\n",
    "    for im in imgList:\n",
    "        try:\n",
    "            params.append(im[\"src\"]) #source address of an img in the class rg_i\n",
    "        except KeyError:\n",
    "            params.append(im[\"data-src\"])\n",
    "    return params #return params`\n",
    "\n",
    "# method for downloading imgs from the url\n",
    "def fetch_detail_url():\n",
    "    params = fetch_list_url() #init params by calling the method fetch_list_url()\n",
    "\n",
    "    # print(params)\n",
    "    a = 1 #a = 1\n",
    "    for p in params:\n",
    "        # @param p. the source img urls in params are assigned into p with this foreach-loop if urls are fetched properly   \n",
    "        # @param path; gives download path\n",
    "        # @param a; gives auto-incrementing numeric file name\n",
    "        # finally, set .jpg extension to each of the img downloaded.\n",
    "        urllib.request.urlretrieve(p, 'neckline/4_u_neck/' + str(a) + \".jpg\" )\n",
    "        a+=1 #a = a + 1; increment nums\n",
    "\n",
    "#by calling the method fetch_detail_url(), the method fetch_list_url() is executed first in it.\n",
    "fetch_detail_url() #fetch_detail_url()\n",
    "browser.quit() #close the browser\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. V넥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate browser\n",
    "#binary = r'C:\\Users\\HP\\Desktop\\chromedriver\\chromedriver.exe' #path to the chrome driver\n",
    "#browser = webdriver.Chrome(binary) #init browser - # Optional argument, if not specified will search path.\n",
    "browser = webdriver.Chrome() #init browser\n",
    "\n",
    "#get browser. this will open a new ready-for-searching tab of Chrome browser\n",
    "browser.get(\"https://www.google.com/imghp?hl=en&search?hl=en&q=\") \n",
    "\n",
    "elem = browser.find_element_by_name(\"q\") #init elem\n",
    "elem.send_keys(\"V넥\") #keywords that you wanna use to search\n",
    "time.sleep(3)\n",
    "elem.submit() #elem.submit()\n",
    "\n",
    "# for-loop \n",
    "for i in range(1 ,6):\n",
    "    # find body tag and execute send_keys(Keys.END) for i < 10 so 9 times\n",
    "    # Keys.END is when the END key is executed to be cliecked\n",
    "    browser.find_element_by_xpath(\"//body\").send_keys(Keys.END)  #smb == when clicking show more result button\n",
    "    try:\n",
    "        browser.find_element_by_id(\"smb\").click()\n",
    "        time.sleep(5)\n",
    "    except:\n",
    "        time.sleep(5)\n",
    "time.sleep(5)\n",
    "\n",
    "html = browser.page_source # get page_source from browser\n",
    "\n",
    "# init soup by calling the method BeautifulSoup with the parameters; the variable html and \"html.parser\"\n",
    "soup = BeautifulSoup(html, \"html.parser\") #this code enables you to fetch the image urls and download the images\n",
    "\n",
    "# method for listing url\n",
    "def fetch_list_url():\n",
    "    params = [] #declare and init an array\n",
    "\n",
    "    # find all img tags and the class whose name is rg_i\n",
    "    imgList = soup.find_all(\"img\", class_ =\"rg_i\")\n",
    "\n",
    "    #Now, extract the img sources(urls) from imgList\n",
    "    for im in imgList:\n",
    "        try:\n",
    "            params.append(im[\"src\"]) #source address of an img in the class rg_i\n",
    "        except KeyError:\n",
    "            params.append(im[\"data-src\"])\n",
    "    return params #return params`\n",
    "\n",
    "# method for downloading imgs from the url\n",
    "def fetch_detail_url():\n",
    "    params = fetch_list_url() #init params by calling the method fetch_list_url()\n",
    "\n",
    "    # print(params)\n",
    "    a = 1 #a = 1\n",
    "    for p in params:\n",
    "        # @param p. the source img urls in params are assigned into p with this foreach-loop if urls are fetched properly   \n",
    "        # @param path; gives download path\n",
    "        # @param a; gives auto-incrementing numeric file name\n",
    "        # finally, set .jpg extension to each of the img downloaded.\n",
    "        try: # https 에러가 날 수 있으므로(예방차원) \n",
    "            urllib.request.urlretrieve(p, 'neckline/5_v_neck/' + str(a) + \".jpg\" )\n",
    "            a+=1 #a = a + 1; increment nums\n",
    "        except:\n",
    "            pass\n",
    "#by calling the method fetch_detail_url(), the method fetch_list_url() is executed first in it.\n",
    "fetch_detail_url() #fetch_detail_url()\n",
    "browser.quit() #close the browser\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
